"""
SEO åˆ†æèˆ‡å„ªåŒ–æœå‹™
"""
import re
import logging
from typing import Optional

from google import genai
from google.genai import types

from app.config import settings

logger = logging.getLogger(__name__)


SEO_OPTIMIZE_PROMPT = """ä½ æ˜¯ä¸€ä½ Dcard SEO å„ªåŒ–å°ˆå®¶ã€‚è«‹é‡å°ä»¥ä¸‹æ–‡ç« é€²è¡Œ SEO å„ªåŒ–ï¼Œä½†ä¿æŒåŸæ–‡é¢¨æ ¼å’Œå£èªåŒ–èªæ°£ä¸è®Šã€‚

å„ªåŒ–é‡é»ï¼š
1. åœ¨æ–‡ç« ä¸­è‡ªç„¶åœ°åŠ å…¥æ›´å¤šé•·å°¾é—œéµå­—ï¼ˆæ ¹æ“šç”¢å“é¡å‹æ¨æ¸¬å¸¸è¦‹æœå°‹è©ï¼‰
2. ç¢ºä¿é—œéµå­—å¯†åº¦åœ¨ 1-3% ä¹‹é–“
3. åŠ å¼·å‰è¨€çš„å¸å¼•åŠ›ï¼Œè®“è®€è€…æƒ³ç¹¼çºŒçœ‹
4. å„ªåŒ– FAQ å€å¡Šï¼Œç¢ºä¿å•é¡Œæ˜¯ Google å¸¸è¦‹æœå°‹å•é¡Œ
5. ç¢ºä¿æ–‡ç« å­—æ•¸è‡³å°‘ 1500 å­—
6. ä¿æŒå£èªåŒ–ã€å¹´è¼•åŒ–çš„ Dcard é¢¨æ ¼

âš ï¸ æ ¼å¼è¦å‰‡ï¼š
- ä¸è¦ä½¿ç”¨ä»»ä½• Markdown èªæ³•ï¼ˆä¸è¦ç”¨ **ç²—é«”**ã€### æ¨™é¡Œã€- åˆ—è¡¨ç­‰ï¼‰
- ç›´æ¥ç”¨ç´”æ–‡å­—ï¼Œæ­é…è¡¨æƒ…ç¬¦è™Ÿå’Œåˆ†éš”ç·š(===)æ’ç‰ˆ
- ä¿ç•™åŸæ–‡ä¸­çš„åœ–ç‰‡æ¨™è¨˜ {{IMAGE:...}} ä¸è¦å‹•

âš ï¸ ç¦æ­¢åœ¨æ–‡ç« ä¸­å‡ºç¾ä»»ä½• SEO ç­–ç•¥èªªæ˜æ–‡å­—ï¼ˆä¾‹å¦‚ã€Œæ¶ä½” Google é¦–é ã€ã€Œæå‡æœå°‹æ’åã€ã€Œé•·å°¾é—œéµå­—ã€ç­‰ï¼‰ï¼Œè®€è€…ä¸éœ€è¦çŸ¥é“é€™äº›ã€‚

è«‹ç›´æ¥è¼¸å‡ºå„ªåŒ–å¾Œçš„å®Œæ•´æ–‡ç« ï¼Œä¸è¦åŠ ä»»ä½•è§£é‡‹æˆ–å‰è¨€ã€‚"""


class SeoService:
    """SEO åˆ†ææœå‹™"""

    # è©•åˆ†æ¬Šé‡
    WEIGHTS = {
        "title_length": 20,      # æ¨™é¡Œé•·åº¦ (15-30 å­—)
        "keyword_density": 25,   # é—œéµå­—å¯†åº¦ (1-3%)
        "paragraph_length": 10,  # æ®µè½é•·åº¦
        "content_length": 20,    # å…§å®¹é•·åº¦
        "image_markers": 10,     # åœ–ç‰‡æ¨™è¨˜
        "list_usage": 10,        # åˆ—è¡¨ä½¿ç”¨
        "link_density": 5,       # é€£çµæ¯”ä¾‹
        "readability": 5,        # å¯è®€æ€§
    }

    def __init__(self):
        self._client = None

    @property
    def client(self):
        if self._client is None:
            if not settings.GOOGLE_API_KEY:
                raise ValueError("GOOGLE_API_KEY æœªè¨­å®š")
            self._client = genai.Client(api_key=settings.GOOGLE_API_KEY)
        return self._client

    @staticmethod
    def _extract_keywords_from_title(title: str) -> list:
        """å¾æ¨™é¡Œè‡ªå‹•æå–é—œéµå­—ï¼ˆã€ã€‘å…§çš„è© + ä¸­æ–‡è©çµ„ï¼‰"""
        keywords = []
        # æå–ã€ã€‘å…§çš„é—œéµå­—
        bracket_words = re.findall(r'ã€(.+?)ã€‘', title)
        for w in bracket_words:
            # æ‹†åˆ†å¹´ä»½+é—œéµå­—ï¼Œå¦‚ "2024è²“ç ‚éŸæ¨è–¦" â†’ "è²“ç ‚éŸ", "æ¨è–¦"
            cleaned = re.sub(r'\d{4}', '', w).strip()
            if cleaned:
                keywords.append(cleaned)
        # æå–æœ‰æ„ç¾©çš„ä¸­æ–‡è©çµ„ï¼ˆ2-6å­—ï¼‰
        cn_words = re.findall(r'[\u4e00-\u9fff]{2,6}', title)
        for w in cn_words:
            if w not in keywords and w not in ('å¦‚æœä½ ', 'ç‚ºä»€éº¼', 'æ€éº¼æ¨£', 'å“ªå€‹å¥½'):
                keywords.append(w)
        return keywords[:8]  # æœ€å¤šå– 8 å€‹

    def analyze(self, title: str, content: str, keywords: Optional[list] = None) -> dict:
        """åˆ†ææ–‡ç«  SEO åˆ†æ•¸"""
        scores = {}
        suggestions = []

        # æ²’æœ‰æä¾›é—œéµå­—æ™‚ï¼Œå¾æ¨™é¡Œè‡ªå‹•æå–
        if not keywords:
            keywords = self._extract_keywords_from_title(title)

        # 1. æ¨™é¡Œé•·åº¦ï¼ˆDcard SEO æ¨™é¡Œé€šå¸¸è¼ƒé•·ï¼Œ30-80 å­—ç‚ºæœ€ä½³ï¼‰
        title_len = len(title)
        if 30 <= title_len <= 80:
            scores["title_length"] = self.WEIGHTS["title_length"]
        elif 15 <= title_len <= 120:
            scores["title_length"] = self.WEIGHTS["title_length"] * 0.7
            suggestions.append(f"æ¨™é¡Œé•·åº¦ {title_len} å­—ï¼Œå»ºè­°èª¿æ•´åˆ° 30-80 å­—")
        else:
            scores["title_length"] = self.WEIGHTS["title_length"] * 0.3
            suggestions.append(f"æ¨™é¡Œé•·åº¦ {title_len} å­—ï¼Œåé›¢æœ€ä½³ç¯„åœï¼ˆ30-80 å­—ï¼‰")

        # 2. é—œéµå­—å¯†åº¦
        if keywords:
            total_chars = len(content)
            keyword_count = sum(content.count(kw) for kw in keywords)
            density = (keyword_count * sum(len(kw) for kw in keywords)) / total_chars * 100 if total_chars > 0 else 0

            if 1 <= density <= 3:
                scores["keyword_density"] = self.WEIGHTS["keyword_density"]
            elif 0.5 <= density <= 5:
                scores["keyword_density"] = self.WEIGHTS["keyword_density"] * 0.6
                suggestions.append(f"é—œéµå­—å¯†åº¦ {density:.1f}%ï¼Œå»ºè­°ç¶­æŒåœ¨ 1-3%")
            else:
                scores["keyword_density"] = self.WEIGHTS["keyword_density"] * 0.2
                suggestions.append(f"é—œéµå­—å¯†åº¦ {density:.1f}%ï¼Œéœ€è¦èª¿æ•´")
        else:
            scores["keyword_density"] = self.WEIGHTS["keyword_density"] * 0.5
            suggestions.append("æ¨™é¡Œä¸­æœªèƒ½æå–é—œéµå­—ï¼Œå»ºè­°åŠ å…¥ã€é—œéµå­—ã€‘æ¨™è¨˜")

        # 3. æ®µè½é•·åº¦
        paragraphs = [p.strip() for p in content.split("\n\n") if p.strip()]
        avg_para_len = sum(len(p) for p in paragraphs) / len(paragraphs) if paragraphs else 0
        if 50 <= avg_para_len <= 200:
            scores["paragraph_length"] = self.WEIGHTS["paragraph_length"]
        elif 30 <= avg_para_len <= 300:
            scores["paragraph_length"] = self.WEIGHTS["paragraph_length"] * 0.6
        else:
            scores["paragraph_length"] = self.WEIGHTS["paragraph_length"] * 0.3
            suggestions.append("æ®µè½é•·åº¦ä¸å‡ï¼Œå»ºè­°æ¯æ®µ 50-200 å­—")

        # 4. å…§å®¹é•·åº¦
        content_len = len(content)
        if content_len >= 1500:
            scores["content_length"] = self.WEIGHTS["content_length"]
        elif content_len >= 800:
            scores["content_length"] = self.WEIGHTS["content_length"] * 0.7
            suggestions.append(f"å…§å®¹é•·åº¦ {content_len} å­—ï¼Œå»ºè­°è‡³å°‘ 1500 å­—")
        else:
            scores["content_length"] = self.WEIGHTS["content_length"] * 0.3
            suggestions.append(f"å…§å®¹åƒ… {content_len} å­—ï¼ŒSEO æ•ˆæœæœ‰é™")

        # 5. åœ–ç‰‡æ¨™è¨˜
        image_count = len(re.findall(r'\{\{IMAGE:\d+:\d+\}\}', content))
        if image_count >= 3:
            scores["image_markers"] = self.WEIGHTS["image_markers"]
        elif image_count >= 1:
            scores["image_markers"] = self.WEIGHTS["image_markers"] * 0.6
            suggestions.append(f"ç›®å‰æœ‰ {image_count} å¼µåœ–ç‰‡ï¼Œå»ºè­°è‡³å°‘ 3 å¼µ")
        else:
            scores["image_markers"] = 0
            suggestions.append("æ²’æœ‰åœ–ç‰‡ï¼Œå»ºè­°åŠ å…¥å•†å“åœ–ç‰‡")

        # 6. åˆ—è¡¨ä½¿ç”¨ï¼ˆè¡¨æƒ…ç¬¦è™Ÿé …ç›®ç¬¦è™Ÿä¹Ÿç®—ï¼‰
        list_items = len(re.findall(r'^[-*â—ğŸ‘‰â¡ï¸âœ…âœ¨â¤ï¸ğŸ˜ğŸ’°ğŸ”â“]\s*', content, re.MULTILINE))
        if list_items >= 3:
            scores["list_usage"] = self.WEIGHTS["list_usage"]
        elif list_items >= 1:
            scores["list_usage"] = self.WEIGHTS["list_usage"] * 0.5
        else:
            scores["list_usage"] = 0
            suggestions.append("å»ºè­°ä½¿ç”¨é …ç›®ç¬¦è™Ÿæ•´ç†é‡é»")

        # 7. é€£çµ
        scores["link_density"] = self.WEIGHTS["link_density"] * 0.5

        # 8. å¯è®€æ€§
        scores["readability"] = self.WEIGHTS["readability"] * 0.8

        total_score = sum(scores.values())

        return {
            "score": round(total_score, 1),
            "max_score": 100,
            "grade": self._get_grade(total_score),
            "breakdown": scores,
            "suggestions": suggestions,
            "stats": {
                "title_length": title_len,
                "content_length": content_len,
                "paragraph_count": len(paragraphs),
                "image_count": image_count,
                "list_items": list_items,
            },
        }

    def _get_grade(self, score: float) -> str:
        if score >= 85:
            return "A"
        elif score >= 70:
            return "B"
        elif score >= 50:
            return "C"
        else:
            return "D"

    def optimize_with_llm(self, article) -> dict:
        """ä½¿ç”¨ LLM é€²è¡Œ SEO å„ªåŒ–"""
        content = article.content or ""

        # å…ˆåˆ†æç¾ç‹€
        before_analysis = self.analyze(title=article.title, content=content)

        user_message = f"""ä»¥ä¸‹æ˜¯éœ€è¦ SEO å„ªåŒ–çš„æ–‡ç« ï¼š

æ¨™é¡Œï¼š{article.title}

å…§å®¹ï¼š
{content}

ç›®æ¨™çœ‹æ¿ï¼š{article.target_forum}

ç¾æœ‰ SEO å•é¡Œï¼š
{chr(10).join(f'- {s}' for s in before_analysis['suggestions'])}
"""

        try:
            response = self.client.models.generate_content(
                model=settings.LLM_MODEL,
                contents=user_message,
                config=types.GenerateContentConfig(
                    system_instruction=SEO_OPTIMIZE_PROMPT,
                    temperature=0.5,
                    max_output_tokens=settings.LLM_MAX_TOKENS,
                ),
            )

            optimized_content = response.text
            logger.info(f"SEO LLM å„ªåŒ–å®Œæˆï¼Œæ–‡å­—é•·åº¦: {len(optimized_content)}")

            # æ¸…é™¤å¯èƒ½æ®˜ç•™çš„ Markdown
            from app.services.llm_service import LLMService
            optimized_content = LLMService._strip_markdown(optimized_content)

            # å„ªåŒ–å¾Œé‡æ–°åˆ†æ
            after_analysis = self.analyze(title=article.title, content=optimized_content)

            # è¿½è¹¤ç”¨é‡
            self._track_usage(response)

            return {
                "optimized_content": optimized_content,
                "score": after_analysis["score"],
                "suggestions": after_analysis["suggestions"],
                "before_score": before_analysis["score"],
            }

        except Exception as e:
            logger.error(f"SEO LLM å„ªåŒ–å¤±æ•—: {e}")
            raise RuntimeError(f"SEO å„ªåŒ–å¤±æ•—: {e}")

    def _track_usage(self, response):
        """è¿½è¹¤ API ç”¨é‡"""
        try:
            from app.services.usage_tracker import usage_tracker

            input_tokens = 0
            output_tokens = 0

            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                input_tokens = getattr(response.usage_metadata, 'prompt_token_count', 0) or 0
                output_tokens = getattr(response.usage_metadata, 'candidates_token_count', 0) or 0

            usage_tracker.track(
                requests=1,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
            )
        except Exception as e:
            logger.warning(f"ç”¨é‡è¿½è¹¤å¤±æ•—: {e}")


# å–®ä¾‹
seo_service = SeoService()
